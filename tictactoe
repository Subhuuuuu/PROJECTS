import numpy as np
import random

class TicTacToe:
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.board = np.zeros(9, dtype=int)
        self.player = 1
        self.done = False
        self.winner = None
        return tuple(self.board)
    
    def available_moves(self):
        return [i for i, x in enumerate(self.board) if x == 0]
    
    def make_move(self, move):
        if self.board[move] != 0 or self.done:
            return False
        
        self.board[move] = self.player
        
        # Check win conditions
        wins = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]
        for a, b, c in wins:
            if self.board[a] == self.board[b] == self.board[c] != 0:
                self.done = True
                self.winner = self.player
                return True
        
        # Check draw
        if 0 not in self.board:
            self.done = True
            return True
        
        self.player *= -1
        return True
    
    def display(self):
        symbols = {0: ' ', 1: 'X', -1: 'O'}
        for i in range(0, 9, 3):
            print(f"{symbols[self.board[i]]}|{symbols[self.board[i+1]]}|{symbols[self.board[i+2]]}")
            if i < 6: print("-----")

class QAgent:
    def __init__(self):
        self.q_table = {}
        self.alpha = 0.5
        self.gamma = 0.9
        self.epsilon = 0.1
    
    def get_q(self, state, action):
        return self.q_table.get((state, action), 0)
    
    def choose_action(self, state, moves):
        if not moves:
            return None
            
        if random.random() < self.epsilon:
            return random.choice(moves)
        
        q_values = [self.get_q(state, a) for a in moves]
        max_q = max(q_values)
        best_actions = [a for a, q in zip(moves, q_values) if q == max_q]
        return random.choice(best_actions)
    
    def update(self, state, action, reward, next_state, next_moves):
        old_q = self.get_q(state, action)
        next_max = max([self.get_q(next_state, a) for a in next_moves]) if next_moves else 0
        new_q = old_q + self.alpha * (reward + self.gamma * next_max - old_q)
        self.q_table[(state, action)] = new_q

def train(episodes=10000):
    game = TicTacToe()
    agent_x = QAgent()
    agent_o = QAgent()
    
    for episode in range(episodes):
        state = game.reset()
        
        while not game.done:
            moves = game.available_moves()
            agent = agent_x if game.player == 1 else agent_o
            action = agent.choose_action(state, moves)
            
            prev_state, prev_action = state, action
            game.make_move(action)
            state = tuple(game.board)
            next_moves = game.available_moves()
            
            # Determine reward
            reward = 0
            if game.done:
                if game.winner == 1:  # X wins
                    reward_x, reward_o = 1, -1
                elif game.winner == -1:  # O wins
                    reward_x, reward_o = -1, 1
                else:  # Draw
                    reward_x, reward_o = 0.3, 0.3
                    
                # Update both agents
                if prev_action is not None:
                    if game.player == -1:  # Last move was by X
                        agent_x.update(prev_state, prev_action, reward_x, state, next_moves)
                    else:  # Last move was by O
                        agent_o.update(prev_state, prev_action, reward_o, state, next_moves)
            else:
                # Update the agent that just moved
                if prev_action is not None:
                    agent.update(prev_state, prev_action, reward, state, next_moves)
    
    return agent_x, agent_o

def play_vs_ai(agent):
    game = TicTacToe()
    
    while not game.done:
        game.display()
        
        if game.player == 1:  # Human
            while True:
                try:
                    move = int(input("Your move (0-8): "))
                    if move in game.available_moves():
                        game.make_move(move)
                        break
                    print("Invalid move")
                except:
                    print("Enter a number 0-8")
        else:  # AI
            state = tuple(game.board)
            move = agent.choose_action(state, game.available_moves())
            game.make_move(move)
            print(f"AI plays: {move}")
    
    game.display()
    if game.winner == 1:
        print("You win!")
    elif game.winner == -1:
        print("AI wins!")
    else:
        print("Draw!")

# Train and play
agent_x, _ = train(1000)
play_vs_ai(agent_x)
